import asyncio
import aiohttp
import time
import re
import logging
import os
import gc
from typing import List, Set, Tuple, Optional, Dict, Callable
from collections import defaultdict
from urllib.parse import urlparse
from configparser import ConfigParser
from .models import Channel

logger = logging.getLogger(__name__)

class SpeedTester:
    """é«˜æ€§èƒ½æµåª’ä½“æµ‹é€Ÿå¼•æ“ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰"""

    def __init__(self, 
                 timeout: float = 5.0, 
                 concurrency: int = 10, 
                 max_attempts: int = 3,
                 min_download_speed: float = 100.0, 
                 enable_logging: bool = True,
                 config: Optional[ConfigParser] = None):
        """
        åˆå§‹åŒ–æµ‹é€Ÿå™¨ï¼ˆä¿®å¤Windowsæ–‡ä»¶æè¿°ç¬¦é™åˆ¶ï¼‰
        """
        # Windowsç³»ç»Ÿé™åˆ¶å¹¶å‘æ•°
        if os.name == 'nt':
            max_concurrency = min(concurrency, 30)  # Windowsé™åˆ¶ä¸º30
            if concurrency > max_concurrency:
                logger.warning(f"Windowsç³»ç»Ÿå¹¶å‘æ•°é™åˆ¶ä¸º{max_concurrency}ï¼ˆåŸ{concurrency}ï¼‰")
            self.concurrency = max_concurrency
        else:
            self.concurrency = max(1, min(concurrency, 100))
        
        # åŸºç¡€é…ç½®
        self.timeout = timeout
        self.max_attempts = max(1, max_attempts)
        self.min_download_speed = max(0.1, min_download_speed)
        self._enable_logging = enable_logging
        self.config = config or ConfigParser()

        # ä¸‹è½½é™åˆ¶é…ç½®
        self.max_download_size = self.config.getint(
            'TESTER', 
            'max_download_size', 
            fallback=100 * 1024
        )
        
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        self._init_logger()

        # åè®®æ£€æµ‹
        self.rtp_udp_pattern = re.compile(r'/(rtp|udp)/', re.IGNORECASE)
        
        # åè®®ç‰¹å®šé…ç½®
        self.udp_timeout = self.config.getfloat('TESTER', 'udp_timeout', fallback=max(0.5, timeout * 0.3))
        self.http_timeout = self.config.getfloat('TESTER', 'http_timeout', fallback=timeout)
        self.min_udp_download_speed = self.config.getfloat('TESTER', 'min_udp_download_speed', fallback=30)
        self.max_udp_latency = self.config.getint('TESTER', 'max_udp_latency', fallback=300)
        self.max_http_latency = self.config.getint('TESTER', 'max_http_latency', fallback=1000)
        self.max_channels_per_ip = self.config.getint('TESTER', 'max_channels_per_ip', fallback=100)
        
        # IPé˜²æŠ¤æœºåˆ¶
        self.failed_ips: Dict[str, int] = defaultdict(int)
        self.max_failures_per_ip = self.config.getint('PROTECTION', 'max_failures_per_ip', fallback=5)
        self.blocked_ips: Set[str] = set()
        self.ip_cooldown: Dict[str, float] = {}
        self.min_ip_interval = self.config.getfloat('PROTECTION', 'min_ip_interval', fallback=0.5)
        
        # å¹¶å‘æ§åˆ¶ï¼ˆä¿®å¤å…³é”®ï¼‰
        self._active_tasks = 0
        self._max_active_tasks = self.concurrency
        self._task_condition = asyncio.Condition()
        
        # ç»Ÿè®¡
        self.success_count = 0
        self.total_count = 0
        self.start_time = 0.0

    def _init_logger(self):
        """åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨"""
        self.logger = logging.getLogger('core.tester')
        self.logger.disabled = not self._enable_logging
        
        def make_log_method(level):
            def log_method(msg, *args, **kwargs):
                if self._enable_logging:
                    getattr(self.logger, level)(msg, *args, **kwargs)
            return log_method
        
        self.log = type('LogMethod', (), {
            'debug': make_log_method('debug'),
            'info': make_log_method('info'),
            'warning': make_log_method('warning'),
            'error': make_log_method('error'),
            'exception': make_log_method('exception')
        })()

    async def test_channels(self, 
                          channels: List[Channel], 
                          progress_cb: Optional[Callable] = None,
                          failed_urls: Optional[Set[str]] = None, 
                          white_list: Optional[Set[str]] = None) -> None:
        """
        æ‰¹é‡æµ‹è¯•é¢‘é“ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼Œä¿®å¤æ–‡ä»¶æè¿°ç¬¦é™åˆ¶ï¼‰
        """
        failed_urls = failed_urls or set()
        white_list = white_list or set()
        progress_cb = progress_cb or (lambda _: None)
        
        self.total_count = len(channels)
        self.success_count = 0
        self.start_time = time.time()
        
        self.log.info(
            "â–¶ï¸ å¼€å§‹æµ‹é€Ÿ | æ€»æ•°: %d | å¹¶å‘: %d | å•IPæœ€å¤§é¢‘é“: %d",
            self.total_count, self.concurrency, self.max_channels_per_ip
        )

        # åˆ›å»ºè‡ªå®šä¹‰connectorï¼ˆå…³é”®ä¿®å¤ï¼‰
        connector = aiohttp.TCPConnector(
            limit=self.concurrency,
            force_close=True,
            enable_cleanup_closed=True,
            ssl=False
        )

        try:
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=self.timeout)
            ) as session:
                # ä½¿ç”¨å¸¦é™åˆ¶çš„æ‰¹å¤„ç†
                await self._process_batch_with_limits(
                    session, channels, progress_cb, failed_urls, white_list
                )
                
        except Exception as e:
            self.log.error("æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: %s", str(e))
            if "_abort" not in str(e):
                raise
        finally:
            await connector.close()
            elapsed = time.time() - self.start_time
            success_rate = (self.success_count / self.total_count) * 100 if self.total_count > 0 else 0
            self.log.info(
                "âœ… æµ‹é€Ÿå®Œæˆ | æˆåŠŸ: %d(%.1f%%) | å¤±è´¥: %d | å±è”½IP: %d | ç”¨æ—¶: %.1fs",
                self.success_count, success_rate,
                self.total_count - self.success_count,
                len(self.blocked_ips),
                elapsed
            )

    async def _process_batch_with_limits(self, session, channels, progress_cb, failed_urls, white_list):
        """å¸¦è¿æ¥æ•°é™åˆ¶çš„æ‰¹å¤„ç†"""
        tasks = []
        for channel in channels:
            # ç­‰å¾…å¯ç”¨æ§½ä½
            async with self._task_condition:
                await self._task_condition.wait_for(
                    lambda: self._active_tasks < self._max_active_tasks
                )
                self._active_tasks += 1
            
            # åˆ›å»ºä»»åŠ¡
            task = asyncio.create_task(
                self._test_single_channel_limited(session, channel, progress_cb, failed_urls, white_list)
            )
            tasks.append(task)
        
        # å®‰å…¨æ‰§è¡Œï¼Œé¿å…å¼‚å¸¸ä¼ æ’­
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        for result in results:
            if isinstance(result, Exception):
                self.log.error("ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: %s", str(result))

    async def _test_single_channel_limited(self, session, channel, progress_cb, failed_urls, white_list):
        """å¸¦èµ„æºé™åˆ¶çš„å•é¢‘é“æµ‹è¯•"""
        try:
            await self._test_single_channel(session, channel, progress_cb, failed_urls, white_list)
        except Exception as e:
            self.log.error("é¢‘é“æµ‹è¯•å¼‚å¸¸ %s: %s", channel.name, str(e))
            failed_urls.add(channel.url)
            channel.status = 'offline'
        finally:
            # é‡Šæ”¾æ§½ä½
            async with self._task_condition:
                self._active_tasks -= 1
                self._task_condition.notify_all()
            progress_cb(1)

    async def _test_single_channel(self,
                                 session: aiohttp.ClientSession,
                                 channel: Channel,
                                 progress_cb: Callable,
                                 failed_urls: Set[str],
                                 white_list: Set[str]) -> None:
        """æµ‹è¯•å•ä¸ªé¢‘é“"""
        if self._is_in_white_list(channel, white_list):
            channel.status = 'online'
            self.log.debug("ğŸŸ¢ ç™½åå•è·³è¿‡ %s", channel.name)
            return

        if channel.url in self.blocked_ips:
            channel.status = 'offline'
            failed_urls.add(channel.url)
            return

        try:
            self.log.debug("ğŸ” å¼€å§‹æµ‹è¯• %s", channel.name)

            success, speed, latency = await self._unified_test(session, channel)
            
            if success:
                self._handle_success(channel, speed, latency)
            else:
                self._handle_failure(channel, failed_urls, speed, latency)
                
        except asyncio.TimeoutError:
            self._handle_timeout(channel, failed_urls)
        except aiohttp.ClientError as e:
            self._handle_client_error(channel, failed_urls, e)
        except Exception as e:
            self._handle_error(channel, failed_urls, e)

    async def _unified_test(self,
                          session: aiohttp.ClientSession,
                          channel: Channel) -> Tuple[bool, float, float]:
        """ç»Ÿä¸€æµ‹è¯•æ–¹æ³•ï¼ˆæ”¯æŒUDP/HTTPåè®®ï¼‰"""
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            is_udp = self._is_udp_url(channel.url)
            timeout_val = self.udp_timeout if is_udp else self.http_timeout
            
            # åè®®é˜ˆå€¼
            min_speed = self.min_udp_download_speed if is_udp else self.min_download_speed
            max_latency = self.max_udp_latency if is_udp else self.max_http_latency

            # é˜¶æ®µ1ï¼šå¿«é€ŸHEADè¯·æ±‚æµ‹å»¶è¿Ÿ
            latency_start = time.perf_counter()
            async with session.head(channel.url, headers=headers, timeout=timeout_val) as resp:
                latency = (time.perf_counter() - latency_start) * 1000
                if latency > max_latency or resp.status != 200:
                    return False, 0.0, latency

            # é˜¶æ®µ2ï¼šGETè¯·æ±‚æµ‹é€Ÿåº¦ï¼ˆå¤ç”¨è¿æ¥ï¼‰
            start = time.perf_counter()
            content_size = 0
            
            # ä½¿ç”¨iter_chunkedåˆ†å—è¯»å–ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶
            async with session.get(channel.url, headers=headers, timeout=timeout_val) as resp:
                async for chunk in resp.content.iter_chunked(1024 * 4):  # 4KB chunks
                    content_size += len(chunk)
                    # è¾¾åˆ°æœ€å¤§ä¸‹è½½é‡æ—¶æå‰ç»“æŸ
                    if content_size >= self.max_download_size:
                        break
                
                duration = time.perf_counter() - start
                speed = content_size / duration / 1024 if duration > 0 else 0
                return speed >= min_speed, speed, latency

        except asyncio.TimeoutError:
            return False, 0.0, 0.0
        except aiohttp.ClientError:
            return False, 0.0, 0.0
        except Exception:
            return False, 0.0, 0.0

    def _handle_success(self,
                      channel: Channel,
                      speed: float,
                      latency: float) -> None:
        """å¤„ç†æˆåŠŸç»“æœ"""
        self.success_count += 1
        channel.status = 'online'
        channel.response_time = latency
        channel.download_speed = speed
        
        protocol = "UDP" if self._is_udp_url(channel.url) else "HTTP"
        self.log.info(
            "âœ… æˆåŠŸ | %-5s | %-30s | %6.1fKB/s | %4.0fms | %s",
            protocol, channel.name[:30], speed, latency,
            self._simplify_url(channel.url)
        )

    def _handle_failure(self,
                       channel: Channel,
                       failed_urls: Set[str],
                       speed: float,
                       latency: float) -> None:
        """å¤„ç†å¤±è´¥ç»“æœ"""
        failed_urls.add(channel.url)
        channel.status = 'offline'
        ip = self._extract_ip_from_url(channel.url)
        self.failed_ips[ip] += 1
        
        is_udp = self._is_udp_url(channel.url)
        reason = (
            "é€Ÿåº¦ä¸è¶³" if speed > 0 and speed < (
                self.min_udp_download_speed if is_udp else self.min_download_speed
            ) else
            "å»¶è¿Ÿè¿‡é«˜" if latency > (
                self.max_udp_latency if is_udp else self.max_http_latency
            ) else
            "è¿æ¥å¤±è´¥"
        )
        
        self.log.warning(
            "âŒ å¤±è´¥ | %-5s | %-30s | %6.1fKB/s | %4.0fms | %-8s | %s",
            "UDP" if is_udp else "HTTP",
            channel.name[:30], speed, latency, reason,
            self._simplify_url(channel.url)
        )

    def _handle_timeout(self,
                       channel: Channel,
                       failed_urls: Set[str]) -> None:
        """å¤„ç†è¶…æ—¶"""
        failed_urls.add(channel.url)
        channel.status = 'offline'
        ip = self._extract_ip_from_url(channel.url)
        self.failed_ips[ip] += 1
        
        self.log.warning(
            "â° è¶…æ—¶ | %-30s | %s",
            channel.name[:30],
            self._simplify_url(channel.url)
        )

    def _handle_client_error(self,
                           channel: Channel,
                           failed_urls: Set[str],
                           error: Exception) -> None:
        """å¤„ç†å®¢æˆ·ç«¯é”™è¯¯"""
        failed_urls.add(channel.url)
        channel.status = 'offline'
        ip = self._extract_ip_from_url(channel.url)
        self.failed_ips[ip] += 1
        
        self.log.error(
            "ğŸŒ å®¢æˆ·ç«¯é”™è¯¯ | %-30s | %-20s | %s",
            channel.name[:30], str(error)[:20],
            self._simplify_url(channel.url)
        )

    def _handle_error(self,
                     channel: Channel,
                     failed_urls: Set[str],
                     error: Exception) -> None:
        """å¤„ç†å¼‚å¸¸"""
        failed_urls.add(channel.url)
        channel.status = 'offline'
        ip = self._extract_ip_from_url(channel.url)
        self.failed_ips[ip] += 1
        
        self.log.error(
            "â€¼ï¸ å¼‚å¸¸ | %-30s | %-20s | %s",
            channel.name[:30], str(error)[:20],
            self._simplify_url(channel.url)
        )

    def _is_udp_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºUDPåè®®URL"""
        url_lower = url.lower()
        return (url_lower.startswith(('udp://', 'rtp://')) or 
                bool(self.rtp_udp_pattern.search(url_lower)))

    def _extract_ip_from_url(self, url: str) -> str:
        """ä»URLæå–IPåœ°å€"""
        try:
            parsed = urlparse(url)
            netloc = parsed.netloc.split('@')[-1]
            if '[' in netloc and ']' in netloc:  # IPv6
                return netloc.split(']')[0] + ']'
            return netloc.split(':')[0]  # IPv4
        except:
            return "unknown"

    def _simplify_url(self, url: str) -> str:
        """ç®€åŒ–URLæ˜¾ç¤º"""
        return url[:100] + '...' if len(url) > 100 else url

    def _is_in_white_list(self,
                        channel: Channel,
                        white_list: Set[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­"""
        if not white_list:
            return False
        return channel.name.lower() in white_list

    def _group_channels_by_ip(self, 
                            channels: List[Channel],
                            white_list: Set[str]) -> Dict[str, List[Channel]]:
        """
        æ”¹è¿›ç‰ˆIPåˆ†ç»„é€»è¾‘
        è¿”å›: { "ip_0": [ch1,ch2...], "ip_1": [...] }
        """
        groups = defaultdict(list)
        ip_counter = defaultdict(int)
        
        # ç™½åå•ç‹¬ç«‹åˆ†ç»„
        whitelist_group = [ch for ch in channels if self._is_in_white_list(ch, white_list)]
        if whitelist_group:
            groups["whitelist"] = whitelist_group
        
        # å¸¸è§„åˆ†ç»„
        for ch in channels:
            if self._is_in_white_list(ch, white_list):
                continue
                
            ip = self._extract_ip_from_url(ch.url)
            group_idx = ip_counter[ip] // self.max_channels_per_ip
            group_key = f"{ip}_{group_idx}"
            
            groups[group_key].append(ch)
            ip_counter[ip] += 1
            
            self.log.debug("IP %s é¢‘é“æ•°è¶…è¿‡ %dï¼Œåˆ›å»ºåˆ†ç»„ %s", 
                         ip, self.max_channels_per_ip, group_key)
        
        return groups

    def clear_resources(self):
        """æ¸…ç†èµ„æº"""
        self.failed_ips.clear()
        self.blocked_ips.clear()
        self.ip_cooldown.clear()
        self._active_tasks = 0
        gc.collect()